---
title: "Audioscribe Quickstart Guide: Get Started in 5 Minutes"
description: "Complete Audioscribe tutorial with code examples in Python, Node.js, JavaScript, and curl. Learn how to transcribe audio files in minutes with our step-by-step quickstart guide."
date: "2024-01-18"
author: "Audioscribe Team"
category: "Tutorial"
tags: ["whisperapi tutorial", "quickstart", "api integration", "speech to text", "getting started"]
readingTime: "10 min read"
image: "/blog/whisperapi-quickstart-cover.jpg"
featured: true
seo:
  metaTitle: "Audioscribe Tutorial: Complete Quickstart Guide in 5 Minutes | Code Examples"
  metaDescription: "Learn how to use Audioscribe with our comprehensive tutorial. Includes code examples in Python, Node.js, JavaScript, and curl. Start transcribing audio in 5 minutes."
  keywords: "whisperapi tutorial, whisperapi quickstart, audio transcription api, speech to text api, whisperapi guide, whisperapi examples"
  ogImage: "/blog/whisperapi-quickstart-og.jpg"
  ogType: "article"
  twitterCard: "summary_large_image"
---

# Audioscribe Quickstart Guide: Get Started in 5 Minutes

Welcome to the Audioscribe quickstart guide! Whether you're building a podcast transcription service, adding voice notes to your application, or creating an accessibility tool, Audioscribe makes it incredibly simple to convert speech to text with state-of-the-art accuracy.

In this comprehensive tutorial, you'll learn everything you need to get started with Audioscribe in just 5 minutes. We'll walk through account setup, authentication, and making your first API call. You'll find complete code examples in four popular programming languages (Python, Node.js, JavaScript, and curl), troubleshooting tips, and best practices to help you build production-ready applications.

By the end of this guide, you'll have successfully transcribed your first audio file and understand how to integrate Audioscribe into your own projects. Whether you're a complete beginner or an experienced developer, this step-by-step tutorial will get you up and running quickly.

**Ready to transform audio into text?** Let's dive in and make your first API call within the next few minutes.

## Account Setup

Setting up your Audioscribe account is quick and straightforward. Follow these steps to get started:

### Create Your Account

1. **Visit the signup page**: Navigate to [Audioscribe Signup](/signup) and click "Get Started Free"
2. **Choose your plan**: Start with our generous free tier that includes 100 minutes of transcription per month—perfect for testing and small projects
3. **Enter your details**: Provide your email address, create a secure password, and verify your email
4. **Complete verification**: Check your inbox for a verification email and click the confirmation link

![Audioscribe Signup Dashboard](/blog/screenshots/whisperapi-signup-dashboard.png)

### Understanding the Dashboard

Once you log in, you'll see your dashboard with several key sections:

- **API Usage Metrics**: Track your monthly transcription minutes, API calls, and quota remaining
- **API Keys Management**: Generate, view, and revoke API keys securely
- **Billing & Plans**: Monitor your current plan, upgrade options, and billing history
- **Documentation**: Quick links to API docs, code examples, and support resources
- **Recent Transcriptions**: View your latest API calls, response times, and transcription status

### Choose Your Plan

Audioscribe offers flexible pricing to match your needs:

- **Free Tier**: 100 minutes/month, perfect for testing and development
- **Starter Plan**: $29/month for 1,000 minutes with priority support
- **Professional Plan**: $99/month for 5,000 minutes with advanced features
- **Enterprise Plan**: Custom pricing with dedicated support and SLA guarantees

All plans include the same high-quality transcription accuracy, multiple language support (95+ languages), and advanced features like speaker diarization and timestamps. You can upgrade or downgrade your plan anytime directly from your dashboard.

**Pro Tip**: Start with the free tier to test Audioscribe with your use case before committing to a paid plan. Most developers find they can build and test their entire integration within the free quota.

![Audioscribe Pricing Tiers](/blog/screenshots/whisperapi-pricing-dashboard.png)

## Get Your API Key

Your API key is the credential you'll use to authenticate all requests to Audioscribe. Here's how to generate and manage your keys securely.

### Generating Your First API Key

1. **Navigate to API Keys**: From your dashboard, click on "API Keys" in the left sidebar
2. **Click "Create New Key"**: A modal will appear asking you to name your key
3. **Name your key**: Use descriptive names like "Production App" or "Development Testing" to help you manage multiple keys
4. **Copy your key**: Your new API key will be displayed **only once**—make sure to copy it immediately and store it securely

![API Key Generation Screen](/blog/screenshots/whisperapi-key-generation.png)

### Secure Key Management Best Practices

**Never commit API keys to version control.** Instead, use environment variables to store your keys:

```bash
# Add to your .env file (never commit this file!)
WHISPERAPI_KEY=wsk_live_1234567890abcdef1234567890abcdef
```

```bash
# Add .env to your .gitignore
echo ".env" >> .gitignore
```

### Key Management Tips

- **Use separate keys for different environments**: Create distinct keys for development, staging, and production
- **Rotate keys regularly**: Update your API keys every 90 days for enhanced security
- **Revoke compromised keys immediately**: If a key is exposed, revoke it from your dashboard and generate a new one
- **Monitor key usage**: Track which keys are being used and their request patterns to detect unusual activity
- **Set up rate limiting**: Configure rate limits for each key to prevent accidental overuse

Your API key format will look like this: `wsk_live_` followed by a 32-character alphanumeric string. Test keys (for sandbox environments) begin with `wsk_test_` instead.

**Ready to make your first API call?** Let's start with a simple curl example to verify your setup.

## First API Call with curl

Let's make your first transcription request using curl—a simple command-line tool available on most systems. This is the fastest way to verify your API key works correctly.

### Basic Transcription Request

Here's the simplest possible transcription request. Save an audio file (MP3, WAV, M4A, or other supported formats) and run this command:

```bash
curl -X POST https://api.audiscribe.com/v1/transcribe \
  -H "Authorization: Bearer wsk_live_YOUR_API_KEY_HERE" \
  -F "file=@/path/to/your/audio.mp3" \
  -F "language=en"
```

Replace `wsk_live_YOUR_API_KEY_HERE` with your actual API key and update the file path to point to your audio file.

### Understanding the Response

You'll receive a JSON response that looks like this:

```json
{
  "id": "txn_1234567890abcdef",
  "status": "completed",
  "text": "Welcome to Audioscribe. This is your first transcription.",
  "language": "en",
  "duration": 3.5,
  "segments": [
    {
      "id": 0,
      "start": 0.0,
      "end": 1.5,
      "text": "Welcome to Audioscribe.",
      "confidence": 0.98
    },
    {
      "id": 1,
      "start": 1.5,
      "end": 3.5,
      "text": "This is your first transcription.",
      "confidence": 0.97
    }
  ],
  "words": [
    {
      "word": "Welcome",
      "start": 0.0,
      "end": 0.4,
      "confidence": 0.99
    }
  ]
}
```

### Advanced Options

Enhance your transcription with additional parameters:

```bash
curl -X POST https://api.audiscribe.com/v1/transcribe \
  -H "Authorization: Bearer wsk_live_YOUR_API_KEY_HERE" \
  -F "file=@/path/to/your/audio.mp3" \
  -F "language=en" \
  -F "response_format=srt" \
  -F "timestamp_granularities[]=word" \
  -F "timestamp_granularities[]=segment"
```

**Available Parameters:**
- `language`: ISO language code (en, es, fr, etc.) - auto-detected if omitted
- `response_format`: json (default), text, srt, vtt, verbose_json
- `timestamp_granularities`: word-level and/or segment-level timestamps
- `temperature`: 0.0-1.0, controls randomness (default: 0)
- `prompt`: Optional text to guide transcription style or vocabulary

### Testing Different Audio Formats

Audioscribe supports a wide range of audio formats. Test with different file types:

```bash
# MP3 audio
curl -X POST https://api.audiscribe.com/v1/transcribe \
  -H "Authorization: Bearer wsk_live_YOUR_API_KEY_HERE" \
  -F "file=@podcast.mp3"

# WAV audio
curl -X POST https://api.audiscribe.com/v1/transcribe \
  -H "Authorization: Bearer wsk_live_YOUR_API_KEY_HERE" \
  -F "file=@recording.wav"

# M4A audio (common for voice memos)
curl -X POST https://api.audiscribe.com/v1/transcribe \
  -H "Authorization: Bearer wsk_live_YOUR_API_KEY_HERE" \
  -F "file=@voice-note.m4a"
```

**Supported formats**: MP3, MP4, MPEG, MPGA, M4A, WAV, WEBM, OGG, FLAC

**File size limit**: 25 MB per request. For larger files, consider compressing the audio or splitting it into chunks.

![curl Command Success Response](/blog/screenshots/whisperapi-curl-success.png)

**Congratulations!** You've made your first successful API call. Now let's explore how to integrate Audioscribe into your applications using popular programming languages.

## Python Example

Python is one of the most popular languages for working with APIs. Here's a complete guide to integrating Audioscribe into your Python applications.

### Installation

First, install the required library:

```bash
pip install requests python-dotenv
```

### Basic Transcription Script

Create a file called `transcribe.py`:

```python
import requests
import os
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Your API key from environment variable
API_KEY = os.getenv('WHISPERAPI_KEY')
API_URL = 'https://api.audiscribe.com/v1/transcribe'

def transcribe_audio(file_path, language='en'):
    """
    Transcribe an audio file using Audioscribe

    Args:
        file_path (str): Path to the audio file
        language (str): Language code (default: 'en')

    Returns:
        dict: Transcription result
    """
    headers = {
        'Authorization': f'Bearer {API_KEY}'
    }

    with open(file_path, 'rb') as audio_file:
        files = {
            'file': audio_file
        }
        data = {
            'language': language,
            'response_format': 'verbose_json',
            'timestamp_granularities[]': ['word', 'segment']
        }

        response = requests.post(API_URL, headers=headers, files=files, data=data)
        response.raise_for_status()

        return response.json()

# Example usage
if __name__ == '__main__':
    try:
        result = transcribe_audio('audio.mp3', language='en')

        print('Transcription:', result['text'])
        print('Duration:', result['duration'], 'seconds')
        print('Language:', result['language'])

        # Print segments with timestamps
        print('\nSegments:')
        for segment in result['segments']:
            print(f"[{segment['start']:.2f}s - {segment['end']:.2f}s] {segment['text']}")

    except requests.exceptions.RequestException as e:
        print(f'Error: {e}')
```

### Advanced Example with Error Handling

Here's a more robust implementation with comprehensive error handling:

```python
import requests
import os
import json
from typing import Optional, Dict, List
from pathlib import Path

class AudioscribeClient:
    """Audioscribe client with error handling and advanced features"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = 'https://api.audiscribe.com/v1'
        self.session = requests.Session()
        self.session.headers.update({
            'Authorization': f'Bearer {api_key}'
        })

    def transcribe(
        self,
        file_path: str,
        language: Optional[str] = None,
        response_format: str = 'json',
        temperature: float = 0.0,
        prompt: Optional[str] = None
    ) -> Dict:
        """
        Transcribe audio file with advanced options

        Args:
            file_path: Path to audio file
            language: Language code (auto-detect if None)
            response_format: Output format (json, text, srt, vtt)
            temperature: Sampling temperature (0.0 - 1.0)
            prompt: Optional context for better accuracy

        Returns:
            Transcription result dictionary
        """
        file_path = Path(file_path)

        if not file_path.exists():
            raise FileNotFoundError(f'Audio file not found: {file_path}')

        if file_path.stat().st_size > 25 * 1024 * 1024:  # 25 MB limit
            raise ValueError('File size exceeds 25 MB limit')

        with open(file_path, 'rb') as audio_file:
            files = {'file': audio_file}
            data = {
                'response_format': response_format,
                'temperature': temperature
            }

            if language:
                data['language'] = language
            if prompt:
                data['prompt'] = prompt

            try:
                response = self.session.post(
                    f'{self.base_url}/transcribe',
                    files=files,
                    data=data,
                    timeout=300  # 5 minute timeout
                )
                response.raise_for_status()
                return response.json()

            except requests.exceptions.HTTPError as e:
                if response.status_code == 401:
                    raise ValueError('Invalid API key')
                elif response.status_code == 429:
                    raise ValueError('Rate limit exceeded')
                else:
                    raise Exception(f'API error: {e}')

    def save_transcript(self, result: Dict, output_file: str):
        """Save transcription result to file"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)

# Example usage
if __name__ == '__main__':
    client = AudioscribeClient(api_key=os.getenv('WHISPERAPI_KEY'))

    result = client.transcribe(
        'interview.mp3',
        language='en',
        prompt='This is a podcast interview about technology'
    )

    client.save_transcript(result, 'transcript.json')
    print(f'Transcribed {result["duration"]:.1f} seconds of audio')
```

### Batch Processing Multiple Files

Process multiple audio files efficiently:

```python
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

def batch_transcribe(audio_files: List[str], max_workers: int = 3):
    """Transcribe multiple files in parallel"""
    client = AudioscribeClient(api_key=os.getenv('WHISPERAPI_KEY'))
    results = {}

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_file = {
            executor.submit(client.transcribe, file): file
            for file in audio_files
        }

        for future in as_completed(future_to_file):
            file = future_to_file[future]
            try:
                results[file] = future.result()
                print(f'✓ Completed: {file}')
            except Exception as e:
                print(f'✗ Failed {file}: {e}')

    return results

# Process all MP3 files in a directory
audio_files = list(Path('audio/').glob('*.mp3'))
results = batch_transcribe(audio_files)
```

**Best Practices:**
- Always use environment variables for API keys
- Implement proper error handling for network issues
- Respect rate limits with batch processing delays
- Save transcription results for debugging and auditing

**Next:** [Try our interactive Python Jupyter notebook →](/docs/python-notebook)

## Node.js Example

Node.js developers can easily integrate Audioscribe using the built-in fetch API or popular libraries. Here's everything you need to know.

### Installation

Create a new Node.js project and install dependencies:

```bash
npm init -y
npm install dotenv form-data node-fetch
```

### Basic Transcription with Node.js

Create `transcribe.js`:

```javascript
const fs = require('fs');
const FormData = require('form-data');
const fetch = require('node-fetch');
require('dotenv').config();

const API_KEY = process.env.WHISPERAPI_KEY;
const API_URL = 'https://api.audiscribe.com/v1/transcribe';

async function transcribeAudio(filePath, language = 'en') {
  const form = new FormData();
  form.append('file', fs.createReadStream(filePath));
  form.append('language', language);
  form.append('response_format', 'verbose_json');

  const response = await fetch(API_URL, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${API_KEY}`,
      ...form.getHeaders()
    },
    body: form
  });

  if (!response.ok) {
    throw new Error(`API error: ${response.statusText}`);
  }

  return await response.json();
}

// Example usage
async function main() {
  try {
    const result = await transcribeAudio('audio.mp3');

    console.log('Transcription:', result.text);
    console.log('Duration:', result.duration, 'seconds');

    // Display segments with timestamps
    console.log('\nSegments:');
    result.segments.forEach(segment => {
      console.log(`[${segment.start.toFixed(2)}s - ${segment.end.toFixed(2)}s] ${segment.text}`);
    });

  } catch (error) {
    console.error('Error:', error.message);
  }
}

main();
```

### Advanced Node.js Implementation

Here's a more sophisticated implementation with TypeScript support:

```javascript
const fs = require('fs').promises;
const path = require('path');
const FormData = require('form-data');
const fetch = require('node-fetch');

class AudioscribeClient {
  constructor(apiKey) {
    this.apiKey = apiKey;
    this.baseUrl = 'https://api.audiscribe.com/v1';
  }

  async transcribe(filePath, options = {}) {
    const {
      language = null,
      responseFormat = 'json',
      temperature = 0.0,
      prompt = null,
      timestampGranularities = ['segment']
    } = options;

    // Validate file exists and size
    const stats = await fs.stat(filePath);
    if (stats.size > 25 * 1024 * 1024) {
      throw new Error('File size exceeds 25 MB limit');
    }

    // Prepare form data
    const form = new FormData();
    form.append('file', await fs.readFile(filePath), {
      filename: path.basename(filePath)
    });
    form.append('response_format', responseFormat);
    form.append('temperature', temperature.toString());

    if (language) form.append('language', language);
    if (prompt) form.append('prompt', prompt);

    timestampGranularities.forEach(granularity => {
      form.append('timestamp_granularities[]', granularity);
    });

    // Make API request
    const response = await fetch(`${this.baseUrl}/transcribe`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.apiKey}`,
        ...form.getHeaders()
      },
      body: form
    });

    // Handle errors
    if (!response.ok) {
      const error = await response.json().catch(() => ({}));
      throw new Error(error.message || `HTTP ${response.status}: ${response.statusText}`);
    }

    return await response.json();
  }

  async saveTranscript(result, outputPath) {
    await fs.writeFile(
      outputPath,
      JSON.stringify(result, null, 2),
      'utf-8'
    );
  }
}

// Express.js integration example
const express = require('express');
const multer = require('multer');
const upload = multer({ dest: 'uploads/' });
const app = express();

app.post('/api/transcribe', upload.single('audio'), async (req, res) => {
  try {
    const client = new AudioscribeClient(process.env.WHISPERAPI_KEY);
    const result = await client.transcribe(req.file.path, {
      language: req.body.language || 'en'
    });

    // Clean up uploaded file
    await fs.unlink(req.file.path);

    res.json(result);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

app.listen(3000, () => {
  console.log('Transcription API server running on port 3000');
});
```

### Real-time Streaming Example

Process transcription results as they arrive:

```javascript
async function transcribeWithProgress(filePath) {
  const client = new AudioscribeClient(process.env.WHISPERAPI_KEY);

  console.log('Starting transcription...');
  const startTime = Date.now();

  const result = await client.transcribe(filePath, {
    language: 'en',
    timestampGranularities: ['word', 'segment']
  });

  const duration = ((Date.now() - startTime) / 1000).toFixed(2);
  console.log(`Completed in ${duration}s`);

  // Stream segments to console
  for (const segment of result.segments) {
    console.log(`\n[${segment.start.toFixed(1)}s]`);
    console.log(segment.text);

    // Simulate real-time display
    await new Promise(resolve => setTimeout(resolve, 100));
  }

  return result;
}
```

**Pro Tip:** Use async/await for cleaner error handling and combine with Express.js to build a complete transcription API backend.

**Download:** [Complete Node.js example project on GitHub →](https://github.com/whisperapi/nodejs-examples)

## JavaScript (Browser) Example

Building a browser-based transcription interface is simple with Audioscribe. Here's how to create a modern, client-side application.

### HTML Upload Form

Create a simple HTML interface:

```html
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Audioscribe Browser Demo</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      max-width: 800px;
      margin: 50px auto;
      padding: 20px;
    }
    .upload-zone {
      border: 2px dashed #ccc;
      border-radius: 8px;
      padding: 40px;
      text-align: center;
      cursor: pointer;
      transition: all 0.3s;
    }
    .upload-zone:hover {
      border-color: #4F46E5;
      background-color: #f9fafb;
    }
    .result {
      margin-top: 30px;
      padding: 20px;
      background: #f3f4f6;
      border-radius: 8px;
    }
    .segment {
      margin: 10px 0;
      padding: 10px;
      background: white;
      border-radius: 4px;
    }
    .timestamp {
      color: #6b7280;
      font-size: 0.875rem;
    }
  </style>
</head>
<body>
  <h1>Audioscribe Browser Demo</h1>

  <div class="upload-zone" id="uploadZone">
    <input type="file" id="audioFile" accept="audio/*" style="display: none">
    <p>Click to select or drag and drop an audio file</p>
    <p style="color: #6b7280; font-size: 0.875rem">Supported formats: MP3, WAV, M4A, OGG</p>
  </div>

  <div id="status" style="margin-top: 20px;"></div>
  <div id="result" class="result" style="display: none;"></div>

  <script src="transcribe.js"></script>
</body>
</html>
```

### JavaScript Client Implementation

Create `transcribe.js`:

```javascript
// Note: In production, use a backend proxy to secure your API key
const API_KEY = 'wsk_live_YOUR_API_KEY_HERE'; // Never expose in production!
const API_URL = 'https://api.audiscribe.com/v1/transcribe';

class AudioscribeClient {
  constructor(apiKey) {
    this.apiKey = apiKey;
  }

  async transcribe(file, options = {}) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('language', options.language || 'en');
    formData.append('response_format', 'verbose_json');
    formData.append('timestamp_granularities[]', 'segment');

    const response = await fetch(API_URL, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.apiKey}`
      },
      body: formData
    });

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.message || 'Transcription failed');
    }

    return await response.json();
  }
}

// UI handling
const uploadZone = document.getElementById('uploadZone');
const audioFileInput = document.getElementById('audioFile');
const statusDiv = document.getElementById('status');
const resultDiv = document.getElementById('result');

uploadZone.addEventListener('click', () => audioFileInput.click());

uploadZone.addEventListener('dragover', (e) => {
  e.preventDefault();
  uploadZone.style.borderColor = '#4F46E5';
});

uploadZone.addEventListener('dragleave', () => {
  uploadZone.style.borderColor = '#ccc';
});

uploadZone.addEventListener('drop', async (e) => {
  e.preventDefault();
  uploadZone.style.borderColor = '#ccc';

  const file = e.dataTransfer.files[0];
  if (file && file.type.startsWith('audio/')) {
    await processAudioFile(file);
  } else {
    showStatus('Please select an audio file', 'error');
  }
});

audioFileInput.addEventListener('change', async (e) => {
  const file = e.target.files[0];
  if (file) await processAudioFile(file);
});

async function processAudioFile(file) {
  showStatus('Uploading and transcribing...', 'loading');
  resultDiv.style.display = 'none';

  try {
    const client = new AudioscribeClient(API_KEY);
    const result = await client.transcribe(file);

    displayResult(result);
    showStatus('Transcription complete!', 'success');

  } catch (error) {
    showStatus(`Error: ${error.message}`, 'error');
  }
}

function displayResult(result) {
  let html = `
    <h3>Transcription Result</h3>
    <p><strong>Full Text:</strong></p>
    <p>${result.text}</p>
    <p><strong>Duration:</strong> ${result.duration.toFixed(2)} seconds</p>
    <p><strong>Language:</strong> ${result.language}</p>
    <h4>Segments:</h4>
  `;

  result.segments.forEach(segment => {
    html += `
      <div class="segment">
        <div class="timestamp">${segment.start.toFixed(2)}s - ${segment.end.toFixed(2)}s</div>
        <div>${segment.text}</div>
      </div>
    `;
  });

  resultDiv.innerHTML = html;
  resultDiv.style.display = 'block';
}

function showStatus(message, type) {
  const colors = {
    loading: '#3b82f6',
    success: '#10b981',
    error: '#ef4444'
  };

  statusDiv.innerHTML = `<p style="color: ${colors[type]}">${message}</p>`;
}
```

### React Component Example

For React applications:

```javascript
import React, { useState } from 'react';

function TranscriptionApp() {
  const [transcription, setTranscription] = useState(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);

  const handleFileUpload = async (event) => {
    const file = event.target.files[0];
    if (!file) return;

    setLoading(true);
    setError(null);

    const formData = new FormData();
    formData.append('file', file);
    formData.append('language', 'en');

    try {
      const response = await fetch('https://api.audiscribe.com/v1/transcribe', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.REACT_APP_WHISPERAPI_KEY}`
        },
        body: formData
      });

      if (!response.ok) throw new Error('Transcription failed');

      const result = await response.json();
      setTranscription(result);

    } catch (err) {
      setError(err.message);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="transcription-app">
      <h1>Audio Transcription</h1>

      <input
        type="file"
        accept="audio/*"
        onChange={handleFileUpload}
        disabled={loading}
      />

      {loading && <p>Transcribing...</p>}
      {error && <p style={{ color: 'red' }}>Error: {error}</p>}

      {transcription && (
        <div className="result">
          <h2>Transcription</h2>
          <p>{transcription.text}</p>

          <h3>Segments</h3>
          {transcription.segments.map((segment, idx) => (
            <div key={idx} className="segment">
              <span className="timestamp">
                {segment.start.toFixed(2)}s - {segment.end.toFixed(2)}s
              </span>
              <p>{segment.text}</p>
            </div>
          ))}
        </div>
      )}
    </div>
  );
}

export default TranscriptionApp;
```

**Security Warning:** Never expose your API key in client-side code in production. Always use a backend proxy to make API calls securely.

**Try it live:** [Interactive browser demo →](/demo/browser-transcription)

## Common Errors & Solutions

Here are the most common errors you might encounter and how to resolve them quickly.

### Authentication Errors

**Error:** `401 Unauthorized - Invalid API key`

**Solutions:**
- Verify your API key is correct and copied completely
- Check that you're using the correct key format: `wsk_live_` or `wsk_test_`
- Ensure the Authorization header is formatted correctly: `Bearer wsk_live_...`
- Confirm your API key hasn't been revoked in the dashboard

### File Upload Errors

**Error:** `413 Payload Too Large`

**Solution:** File size exceeds 25 MB limit. Compress your audio file or split it into smaller chunks.

```bash
# Use ffmpeg to compress audio
ffmpeg -i large-file.mp3 -b:a 64k compressed-file.mp3
```

**Error:** `415 Unsupported Media Type`

**Solution:** File format not supported. Convert to a supported format (MP3, WAV, M4A, OGG, FLAC).

### Rate Limiting

**Error:** `429 Too Many Requests`

**Solutions:**
- You've exceeded your plan's rate limit
- Implement exponential backoff retry logic
- Upgrade your plan for higher limits
- Space out batch requests with delays

```python
import time

def transcribe_with_retry(file_path, max_retries=3):
    for attempt in range(max_retries):
        try:
            return client.transcribe(file_path)
        except RateLimitError:
            wait_time = (2 ** attempt) * 1  # Exponential backoff
            print(f'Rate limited. Retrying in {wait_time}s...')
            time.sleep(wait_time)
    raise Exception('Max retries exceeded')
```

### Network and Timeout Errors

**Error:** `Request timeout`

**Solution:** Increase timeout for large files or slow connections:

```python
response = requests.post(API_URL, timeout=300)  # 5 minutes
```

### Language Detection Issues

**Problem:** Incorrect language detected or poor transcription quality

**Solution:** Explicitly specify the language parameter:

```bash
curl -X POST https://api.audiscribe.com/v1/transcribe \
  -H "Authorization: Bearer $API_KEY" \
  -F "file=@audio.mp3" \
  -F "language=es"  # Spanish
```

**Need more help?** Check our [complete troubleshooting guide](/docs/troubleshooting) or [contact support](/support).

## Next Steps

Congratulations! You've successfully made your first Audioscribe calls and learned how to integrate transcription into your applications. Here's what to explore next:

### Explore Advanced Features

- **Speaker Diarization**: Identify and separate multiple speakers in your audio with our advanced diarization feature
- **Custom Vocabulary**: Improve accuracy for domain-specific terms, brand names, or technical jargon
- **Webhook Support**: Receive real-time notifications when transcriptions complete for async workflows
- **Batch Processing API**: Upload multiple files and process them efficiently with our batch endpoint

### Build Something Amazing

Get inspired by what others have built with Audioscribe:

- **Podcast Platforms**: Automated episode transcription for better SEO and accessibility
- **Meeting Assistants**: Real-time note-taking and action item extraction
- **Content Creation Tools**: Video subtitle generation and content repurposing
- **Accessibility Solutions**: Live captioning for events and video content

### Resources & Support

- **[Complete API Documentation](/docs)**: Detailed reference for all endpoints and parameters
- **[Code Examples Repository](https://github.com/whisperapi/examples)**: 20+ production-ready examples
- **[Postman Collection](https://www.postman.com/whisperapi/workspace)**: Import and test all API endpoints
- **[Video Tutorials](/tutorials)**: Step-by-step visual guides and advanced techniques
- **[Community Forum](https://community.audiscribe.com)**: Connect with other developers and share tips

### Download Our Postman Collection

Test all Audioscribe endpoints instantly with our comprehensive Postman collection:

[**Download Postman Collection →**](https://www.postman.com/whisperapi/workspace/whisperapi-collection)

The collection includes:
- Pre-configured authentication
- Example requests for all endpoints
- Sample audio files for testing
- Environment variables setup
- Automated testing scripts

### Start Building Now

Ready to integrate Audioscribe into your production application?

**[Create your free account →](/signup)** and get 100 minutes of transcription to start building today.

**[View pricing plans →](/pricing)** to find the perfect plan for your needs.

**[Schedule a demo →](/demo)** to see Audioscribe in action with our solutions engineers.

### Stay Updated

- **[Subscribe to our newsletter](/newsletter)**: Get monthly tips, new features, and use case inspiration
- **[Follow us on Twitter](https://twitter.com/whisperapi)**: Latest updates and community highlights
- **[Join our Discord](https://discord.gg/whisperapi)**: Real-time help and networking

**Questions?** Our support team is here to help at [support@audiscribe.com](mailto:support@audiscribe.com)

---

**You're now ready to build powerful transcription features into your applications.** We can't wait to see what you create with Audioscribe!
